{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Features.py\n",
      "Imported read.py\n",
      "Imported model.py\n",
      "Imported Selection.py\n",
      "Imported preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "import features\n",
    "import read\n",
    "import model\n",
    "import selection\n",
    "import preprocessing\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Features.py\n",
      "Imported read.py\n",
      "Imported model.py\n",
      "Imported Selection.py\n",
      "Imported preprocessing.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'preprocessing' from 'preprocessing.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Must reload each time you change a Python module\n",
    "reload(features)\n",
    "reload(read)\n",
    "reload(model)\n",
    "reload(selection)\n",
    "reload(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Train users: 20 Num of Test users: 20\n",
      "Read data: 263.846363068\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the text files\n",
    "begin = time.time()\n",
    "vocab, train_raw, test_raw = read.read_tweets(\"../training_set_tweets.txt\", \"../test_set_tweets.txt\")\n",
    "print \"Num of Train users:\", len(train_raw), \"Num of Test users:\", len(test_raw)\n",
    "print \"Read data:\", time.time() - begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the data 1.89853405952\n",
      "Assigned ids to words: 0.0227451324463\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "begin = time.time()\n",
    "vocab, train_word, test_word, train_char, test_char = preprocessing.preprocess(train_raw, test_raw)\n",
    "print \"Preprocessed the data\", time.time() - begin\n",
    "\n",
    "#train_word include a bunch of tags that train_char doesn't.\n",
    "\n",
    "# Assign ids to words\n",
    "vocab_list = list(vocab)\n",
    "vocab_list.sort()\n",
    "begin = time.time()\n",
    "vocab_dict = {}\n",
    "for i in range(len(vocab_list)):\n",
    "    vocab_dict[vocab_list[i]] = i\n",
    "print \"Assigned ids to words:\", time.time() - begin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0 Ugh! Why am I not tirrred? I wish I could sleep through this whole day! <URL>\n",
      "1 <REF> you and Ryllie are two of a kind lol! Ur ridic woman lol\n",
      "2 Just downloaded a calorie counter & burner app on my blackberry.... Knowing how much I take in could be scary! However its gotta be done!\n",
      "3 <REF> pay back is a bitch for <REF> eating our snacks! Unleash scheiber on him & ill stop feeding him dinner & wipeing his bum!\n",
      "4 <REF> dont worry that icecream was a stacey scheu purchase for the forest so eat away... & oh snap!! weezy!! loving it.\n",
      "5 At the brew... Shots shots shots??? <URL>\n",
      "6 Good stuff <REPLY> \"I said it too many times And I still stand firm. You get what you put in And people get what they deserve.\"\n",
      "7 <REPLY> <REF>  Change is healthy, but the way we percieve it at times might not be... (Trust life's purpose for you) #TDL\n",
      "8 Just witnessed my first snow flake of the season... NOOOOOOO!!!\n",
      "9 <NUM>pairs of leggins, <NUM> pair of sweats, <NUM> long sleeve, <NUM> tshirt, <NUM> tank, <NUM> hoodie, <NUM> pairs of socks, <NUM>pair of s\n",
      "10 Usually I love \"super nanny\" buttttt its swearing on me currently! Can't sleep & have been watching it for the past <NUM> hours! Ugh shoot m\n"
     ]
    }
   ],
   "source": [
    "print len(train_word)\n",
    "i = 0\n",
    "for user in train_word:\n",
    "    for tweet in train_word[user]:\n",
    "        if i > 10:\n",
    "            break\n",
    "        print i, tweet\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0 Ugh! Why am I not tirrred? I wish I could sleep through this whole day! \n",
      "1  you and Ryllie are two of a kind lol! Ur ridic woman lol\n",
      "2 Just downloaded a calorie counter & burner app on my blackberry.... Knowing how much I take in could be scary! However its gotta be done!\n",
      "3  pay back is a bitch for  eating our snacks! Unleash scheiber on him & ill stop feeding him dinner & wipeing his bum!\n",
      "4  dont worry that icecream was a stacey scheu purchase for the forest so eat away... & oh snap!! weezy!! loving it.\n",
      "5 At the brew... Shots shots shots??? \n",
      "6 Good stuff  \"I said it too many times And I still stand firm. You get what you put in And people get what they deserve.\"\n",
      "7    Change is healthy, but the way we percieve it at times might not be... (Trust life's purpose for you) #TDL\n",
      "8 Just witnessed my first snow flake of the season... NOOOOOOO!!!\n",
      "9 pairs of leggins,  pair of sweats,  long sleeve,  tshirt,  tank,  hoodie,  pairs of socks, pair of slippers,  blankets & still cold\n",
      "10 Usually I love \"super nanny\" buttttt its swearing on me currently! Can't sleep & have been watching it for the past  hours! Ugh shoot me\n"
     ]
    }
   ],
   "source": [
    "print len(train_char)\n",
    "i = 0\n",
    "for user in train_char:\n",
    "    for tweet in train_char[user]:\n",
    "        if i > 10:\n",
    "            break\n",
    "        print i, tweet\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19731\n",
      "1043\n"
     ]
    }
   ],
   "source": [
    "# Build train and test set\n",
    "num_full_feats = len(vocab_list) + 10\n",
    "num_train_tweets = 0\n",
    "num_test_tweets = 0\n",
    "# num_train_tweets = np.count_nonzero(~np.isnan(train))\n",
    "# num_test_tweets = np.count_nonzero(~np.isnan(test))\n",
    "for author_id in train:\n",
    "    num_train_tweets += len(train[author_id])\n",
    "for author_id in test:\n",
    "    num_test_tweets += len(test[author_id])\n",
    "X_train = np.zeros((num_train_tweets, num_full_feats))\n",
    "y_train = np.zeros(num_train_tweets)\n",
    "X_test = np.zeros((num_test_tweets, num_full_feats))\n",
    "y_test = np.zeros(num_test_tweets)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for author_id in train:\n",
    "    for tweet in train[author_id]:\n",
    "        X_train[count, :] = features.get_full_feats(tweet, vocab_dict)\n",
    "        y_train[count] = author_id\n",
    "        count += 1\n",
    "print count\n",
    "\n",
    "count = 0\n",
    "for author_id in test:\n",
    "    for tweet in test[author_id]:\n",
    "        X_test[count, :] = features.get_full_feats(tweet, vocab_dict)\n",
    "        y_test[count] = author_id\n",
    "        count += 1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19731 1043\n",
      "22258\n",
      "['a', 'aa', 'aaa', 'aaaaaaaaaaaaaaahhhhhhhhhhh', 'aaaaaaaaameenah', 'aaaaaaaaanyways', 'aaaaaaaahi', 'aaaaaaannnnddddd', 'aaaaaaawwwwwwwwww', 'aaaaaahhhlets', 'aaaaah', 'aaaaahcough', 'aaaahh', 'aaaahhhhhhh', 'aaaalllll', 'aaaameeeen', 'aaahhh', 'aaahs', 'aaand', 'aack', 'aah', 'aahhh', 'aahhhh', 'aahhhhhhh', 'aaliyah', 'aamir', 'aand', 'aaron', 'aauw', 'aawesome', 'aawww', 'ab', 'abandoned', 'abandoning', 'abba', 'abbotts', 'abbrev', 'abbreviation', 'abbs', 'abc', 'abcd', 'abdc', 'abdomen', 'abe', 'abilities', 'ability', 'abk', 'ablaze', 'able', 'abolish', 'abomination', 'aborted', 'abortin', 'abortion', 'abortions', 'abouit', 'abound', 'about', 'abouta', 'aboutlol', 'aboutsome', 'above', 'abroad', 'absoilutely', 'absoltely', 'absolute', 'absolutely', 'absolutleyyyyy', 'absolutly', 'absur', 'absurd', 'abt', 'abuelito', 'abuse', 'abusive', 'abuuuuut', 'abydosaurus', 'ac', 'aca', 'academies', 'academy', 'academys', 'accelerate', 'accent', 'accentala', 'accents', 'accept', 'acceptable', 'acceptance', 'accepted', 'accepting', 'accepts', 'accesively', 'access', 'accident', 'accidentally', 'accidently', 'accidents', 'accomodate', 'accomplished', 'accomplishments', 'accord', 'accordin', 'according', 'accordions', 'account', 'accountable', 'accountant', 'accounts', 'acct', 'accumulated', 'accurate', 'accuscore', 'accused', 'accuses', 'accustomed', 'acdc', 'acelera', 'acenteno', 'acerca', 'acg', 'ache', 'achieve', 'aching', 'acidcan', 'acidme', 'acitve', 'ack', 'acknowledge', 'acnum', 'acorss', 'acquaintance', 'acquire', 'acquired', 'acre', 'acright', 'acrite', 'acrobat', 'across', 'act', 'acted', 'actin', 'acting', 'action', 'actions', 'actionsinscure', 'actitity', 'active', 'activeinactive', 'activia', 'activist', 'activists', 'activities', 'activity', 'actor', 'actors', 'actress', 'actresses', 'acts', 'actual', 'actually', 'acused', 'ad', 'adam', 'adams', 'adapter', 'add', 'addams', 'added', 'addict', 'addicted', 'addicting', 'addiction', 'addictive', 'addicts', 'adding', 'addison', 'additional', 'additions', 'addmissions', 'addon', 'address', 'addressed', 'addresses', 'addressing', 'adds', 'adele', 'ademas', 'adjust', 'adjusting', 'adlibs', 'admin', 'administrations', 'admirable', 'admiral', 'admire', 'admired', 'admission', 'admist', 'admit', 'admitted', 'admitting', 'adobe', 'adobro', 'adolf', 'adonde', 'adons', 'adopt', 'adopted', 'adoption', 'adoptive', 'adopts', 'adorable', 'adore', 'adores', 'adoubjcdzfofad', 'adrenalin', 'adrian', 'adriana', 'adrianne', 'adrians', 'adrien', 'ads', 'adult', 'adulterers', 'adultfriendfindercom', 'adults', 'advance', 'advances', 'advantage', 'advent', 'adventure', 'adventurer', 'adventures', 'adventurous', 'advenure', 'adversitydont', 'advertise', 'advertiser', 'advertising', 'advice', 'advil', 'advised', 'adviser', 'advisor', 'advisors', 'advisory', 'advocate', 'ae', 'aerial', 'aerobics', 'aeu', 'afa', 'afc', 'affair', 'affairs', 'affect', 'affected', 'affecting', 'affection', 'affectionate', 'affects', 'affiliate', 'affiliatedref', 'affleck', 'affliction', 'afford', 'affordable', 'affordno', 'afghanistan', 'afkjbsr', 'afraid', 'africa', 'african', 'afro', 'aft', 'afta', 'after', 'aftergame', 'aftermath', 'afternoon', 'afternoonlol', 'afternooon', 'afterparty', 'afters', 'aftershock', 'aftershocks', 'aftertaste', 'afterwards', 'afuckingnnoyed', 'ag', 'agaaaaain', 'again', 'againbut', 'againbye', 'againever', 'againgreat', 'againomg', 'against', 'againthank', 'againthanks', 'againts', 'againunknown', 'agaisnt', 'age', 'aged', 'ageeees', 'agency', 'agenda', 'agent', 'agentorange', 'ages', 'aggies', 'aggresive', 'aggressive', 'agh', 'aghh', 'agility', 'aging', 'ago', 'agoi', 'agololi', 'agradecidosi', 'agree', 'agreed', 'agreeee', 'agreeing', 'agreement', 'agrees', 'aguanto', 'ah', 'aha', 'ahaha', 'ahahaha', 'ahahahahha', 'ahahahha', 'ahahahhaha', 'ahahhaa', 'ahahhaha', 'ahater', 'ahead', 'ahells', 'ahem', 'ahh', 'ahhahaha', 'ahhh', 'ahhhahahahahahhahahahahhahahahaah', 'ahhhh', 'ahhhhh', 'ahhhhhh', 'ahhhhhhaaaa', 'ahhhhhhhh', 'ahhhyeeee', 'ahhpoor', 'ahi', 'ahimsa', 'ahmmm', 'ahnold', 'ahoarder', 'ahoe', 'ahold', 'ahole', 'ahora', 'ahuge', 'ah\\xc2\\xb3', 'ai', 'aid', 'aids', 'aight', 'aightyep', 'aihav', 'ails', 'aim', 'aimed', 'aiming', 'aims', 'aint', 'aintnotherb', 'aintnothinglike', 'ainum', 'air', 'airboats', 'airborn', 'aired', 'airemout', 'airing', 'airlift', 'airlifting', 'airlines', 'airplane', 'airporeply', 'airport', 'airs', 'airship', 'airtime', 'aisle', 'aisles', 'aiyou', 'aj', 'aja', 'ajo', 'ak', 'aka', 'akas', 'akineleye', 'akira', 'akon', 'akons', 'al', 'ala', 'alabama', 'alabrasa', 'alack', 'alacran', 'alameda', 'alarm', 'alarmpraying', 'alarms', 'alas', 'alaska', 'alavert', 'alba', 'alberta', 'albino', 'albrecht', 'album', 'albums', 'albumsok', 'albuquerque', 'alchohol', 'alcholic', 'alchy', 'alchywell', 'alcohol', 'alcoholhell', 'alcoholic', 'alcoholics', 'alcs', 'ale', 'alec', 'alejandro', 'alejandroooooo', 'alejannnnndddrrroooooo', 'alereply', 'alert', 'alerts', 'alesina', 'alex', 'alexander', 'alexis', 'alexzjohnson', 'alfb', 'algorithms', 'alguien', 'ali', 'alic', 'alice', 'alicia', 'alidontleaveyes', 'alie', 'alien', 'aliens', 'alike', 'alinghi', 'alis', 'alisa', 'alittle', 'aliv', 'alive', 'alivemeans', 'alivewass', 'alka', 'all', 'allah', 'alldecade', 'alldoneuhu', 'alleged', 'allegedly', 'allen', 'allergic', 'allergies', 'allergy', 'alley', 'alleys', 'alli', 'allialli', 'allie', 'alligators', 'allin', 'allis', 'alliwantforchristmas', 'alll', 'allll', 'alllll', 'allllll', 'allllllll', 'allllllllmost', 'alllol', 'allm', 'allofasudden', 'allover', 'allow', 'allowed', 'allowing', 'allows', 'allready', 'allstar', 'allstarsmuts', 'alltheshade', 'ally', 'almfao', 'almighty', 'almonds', 'almost', 'almst', 'alol', 'alomst', 'alone', 'alonecheese', 'alonewho', 'along', 'alongnowplaying', 'alongside', 'alot', 'alotof', 'alottttttt', 'aloud', 'alpha', 'alphabet', 'alpine', 'alrdy', 'already', 'alreadylol', 'alright', 'alrightdidnt', 'alrighti', 'alrightnothing', 'alrighty', 'alriteim', 'als', 'also', 'alsobut', 'alsololjkwell', 'alsoremember', 'alsowe', 'alt', 'altar', 'alter', 'altho', 'although', 'altima', 'altogether', 'altosget', 'alum', 'alumni', 'alvin', 'always', 'alwys', 'alyssa', 'alzteimers', 'am', 'ama', 'amadvil', 'amanda', 'amanecio', 'amani', 'amarillo', 'amario', 'amatory', 'amazed', 'amazes', 'amazin', 'amazing', 'amazingbut', 'amazinglol', 'amazingly', 'amazingnumi', 'amazng', 'amazon', 'amazoncom', 'amazzzziiinnnggg', 'ambassador', 'amber', 'ambition', 'ambitions', 'ambrose', 'ambulance', 'amc', 'amd', 'amee', 'ameeeventplanningref', 'ameeevents', 'ameica', 'amelia', 'amen', 'amendment', 'amendments', 'amer', 'amercia', 'amereica', 'america', 'american', 'americana', 'americanidol', 'americanized', 'americans', 'americas', 'ami', 'amid', 'amir', 'amish', 'amitheonlyone', 'amityville', 'amlmfao', 'ammmm', 'ammmmm', 'ammmmmazing', 'among', 'amongst', 'amor', 'amorcito', 'amount', 'amp', 'amped', 'ampt', 'ams', 'amt', 'amused', 'amusement', 'amvets', 'amy', 'amyday', 'an', 'ana', 'anaheim', 'anal', 'analing', 'analogy', 'analyst', 'analyze', 'analyzed', 'anasteshia', 'anatomy', 'anchor', 'anchorman', 'anchors', 'and', 'andcancelation', 'anderson', 'andnever', 'andor', 'andreas', 'andrew', 'andris', 'andy', 'angel', 'angela', 'angelamartin', 'angeles', 'angelina', 'angelinas', 'angelique', 'angelitos', 'angelou', 'angels', 'anger', 'angers', 'angigram', 'angrily', 'angry', 'anibal', 'animal', 'animales', 'animals', 'animation', 'animatronic', 'anime', 'aniston', 'ankle', 'ann', 'anna', 'annas', 'annd', 'anne', 'annette', 'annie', 'anniversary', 'annnouce', 'annouced', 'announce', 'announced', 'announcement', 'announcements', 'announcer', 'announces', 'announcing', 'annoy', 'annoyed', 'annoyeddddd', 'annoyin', 'annoying', 'annoyingthebachelor', 'annoys', 'annoyyyyyed', 'annual', 'annyoying', 'anonymous', 'anorak', 'anorexic', 'anot', 'another', 'anotherrpof', 'anothr', 'anout', 'answer', 'answercuz', 'answered', 'answeredthey', 'answering', 'answers', 'antagonizing', 'antartica', 'antes', 'anthem', 'anthony', 'anti', 'antibiotics', 'antichoice', 'antichrist', 'anticipated', 'anticipating', 'anticipation', 'antics', 'anticuddlerbogus', 'antiequality', 'antievangelist', 'antigay', 'antiobama', 'antioch', 'antiques', 'antiquesroadshow', 'antirape', 'antitaylor', 'antone', 'antonio', 'ants', 'antsythese', 'anxiety', 'anxious', 'any', 'anybody', 'anybodys', 'anyhow', 'anymor', 'anymore', 'anymoreloli', 'anymorethis', 'anymoreugh', 'anynum', 'anyome', 'anyone', 'anyonenum', 'anyones', 'anyoneto', 'anys', 'anything', 'anythingi', 'anythinglol', 'anytime', 'anyway', 'anywaybye', 'anywayi', 'anyways', 'anywaysdont', 'anywaysi', 'anywhere', 'anywho', 'anywhohapppy', 'anyyyymore', 'aooww', 'aoowwww', 'aowww', 'ap', 'apach', 'apache', 'apareplyment', 'apart', 'apartment', 'ape', 'apocalypto', 'apointment', 'apologiesi', 'apologix', 'apologize', 'apologized', 'apologizing', 'apology', 'apoplogized', 'app', 'appaerently', 'appalled', 'appaloosa', 'apparel', 'apparent', 'apparently', 'appeal', 'appealed', 'appear', 'appearance', 'appearances', 'appearently', 'appetit', 'appetite', 'appetizer', 'appetizers', 'applaud', 'applauds', 'applause', 'apple', 'applebees', 'apples', 'appleton', 'appliance', 'appliances', 'applicants', 'application', 'applications', 'applied', 'applies', 'apply', 'applying', 'appointed', 'appointees', 'appointment', 'appology', 'appreciate', 'appreciated', 'apprientence', 'approach', 'approached', 'appropriate', 'appropriately', 'approval', 'approve', 'approved', 'approx', 'apps', 'appt', 'appx', 'apraising', 'april', 'aps', 'apt', 'aptly', 'apy', 'aquarius', 'aqui', 'aquinas', 'arab', 'arabi', 'arand', 'arbor', 'arbys', 'arc', 'arcangel', 'arch', 'arctic', 'ard', 'are', 'area', 'areally', 'arealwife', 'areasviejas', 'arebut', 'aregularwoman', 'arena', 'arenatraffic', 'arent', 'aren\\xe2\\x80\\x99t', 'arepa', 'areshrug', 'arewhy', 'are\\xc3\\xa0', 'argentine', 'argh', 'argue', 'arguements', 'argues', 'arguiment', 'arguing', 'argument', 'arguments', 'arias', 'arielwell', 'aristotle', 'arizona', 'ark', 'arkansas', 'arkward', 'arlene', 'arm', 'armani', 'armas', 'armed', 'armenian', 'arms', 'armstrong', 'army', 'arnold', 'arnt', 'aroid', 'around', 'aroundawwwwhat', 'aroundddd', 'aroundi', 'aroundpreachive', 'aroundtruth', 'aroused', 'arrange', 'array', 'arre', 'arrest', 'arrested', 'arrival', 'arrive', 'arrived', 'arrivedwhen', 'arrives', 'arriving', 'arrogance', 'arrogant', 'arrow', 'arrrggh', 'arrrrrggghhh', 'art', 'arte', 'artesans', 'artest', 'arthur', 'article', 'articles', 'artie', 'artificial', 'artisans', 'artist', 'artistas', 'artistic', 'artistry', 'artists', 'arts', 'artst', 'artwork', 'arum', 'ary', 'aryana', 'as', 'asa', 'asaboyfriend', 'asada', 'asap', 'asapppp', 'asassin', 'ash', 'ashanti', 'ashes', 'ashley', 'ashleys', 'ashs', 'ashton', 'ashy', 'asi', 'asian', 'aside', 'asionumall', 'asja', 'ask', 'askd', 'asked', 'askin', 'asking', 'askinim', 'askinwhat', 'asks', 'asl', 'asleep', 'asleeplol', 'aslepp', 'aslong', 'asner', 'asparagus', 'aspect', 'aspects', 'aspiring', 'ass', 'assand', 'assasin', 'assassinating', 'assemble', 'assembly', 'asses']\n"
     ]
    }
   ],
   "source": [
    "print num_train_tweets, num_test_tweets\n",
    "print len(vocab_list) + 10\n",
    "print vocab_list[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.8844139576 acc: 0.547459252157 my_acc: 0.547459252157\n",
      "preds: [ 33642976.  33642976.  17694038. ...,  25892511.  25892511.  33707073.]\n",
      "scores: [[-4.7389232  -2.90169346 -2.70384297 ..., -2.13384256 -2.25636946\n",
      "  -1.55962635]\n",
      " [-4.35259173 -3.05976948 -2.55437753 ..., -2.19848683 -1.96651331\n",
      "  -1.21405561]\n",
      " [-1.72355337 -1.05196641 -0.47439163 ..., -1.99125189 -2.6615657\n",
      "  -1.58766477]\n",
      " ..., \n",
      " [-1.48247037 -2.64560235 -1.74583739 ..., -2.33422935 -2.11687924\n",
      "  -1.96084019]\n",
      " [-1.40102463 -1.69946781 -1.56546975 ..., -1.23615035 -2.13495729\n",
      "  -1.96574758]\n",
      " [-2.14182605 -1.63179234 -2.25505122 ..., -1.38743781 -1.597579\n",
      "  -1.43650198]]\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "clf = model.train(X_train, y_train)\n",
    "acc, my_acc, preds, scores = model.test(clf, X_test, y_test)\n",
    "print 'time:', time.time()-begin, 'acc:', acc, 'my_acc:', my_acc\n",
    "print 'preds:', preds\n",
    "print 'scores:', scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True  True False False  True False  True  True  True\n",
      " False False  True  True  True False  True  True  True  True False False\n",
      " False False  True  True  True False  True False False  True  True  True\n",
      "  True  True  True False  True False False False  True False False  True\n",
      "  True False  True  True  True  True False False  True  True  True False\n",
      "  True  True  True  True  True False False  True False False False False\n",
      " False  True False  True  True  True  True  True  True  True  True False\n",
      "  True False False  True  True False False  True  True  True  True False\n",
      "  True  True  True False]\n"
     ]
    }
   ],
   "source": [
    "print (preds == y_test)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754\n",
      "20106\n"
     ]
    }
   ],
   "source": [
    "print np.count_nonzero(scores > 0)\n",
    "print np.count_nonzero(scores < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
