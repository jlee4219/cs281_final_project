{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import features\n",
    "import read\n",
    "import model\n",
    "import selection\n",
    "import preprocessing\n",
    "import feature_selection\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Features.py\n",
      "Imported read.py\n",
      "Imported model.py\n",
      "Imported Selection.py\n",
      "Imported preprocessing.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'feature_selection' from 'feature_selection.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Must reload each time you change a Python module\n",
    "reload(features)\n",
    "reload(read)\n",
    "reload(model)\n",
    "reload(selection)\n",
    "reload(preprocessing)\n",
    "reload(feature_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Train users: 20 Num of Test users: 20\n",
      "Read data: 918.803701162\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the text files\n",
    "begin = time.time()\n",
    "vocab, train_raw, test_raw = read.read_tweets(\"../training_set_tweets.txt\", \"../test_set_tweets.txt\")\n",
    "print \"Num of Train users:\", len(train_raw), \"Num of Test users:\", len(test_raw)\n",
    "print \"Read data:\", time.time() - begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the data 2.60056209564\n",
      "Assigned ids to words: 0.0144889354706\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "begin = time.time()\n",
    "vocab, train_word, test_word, train_char, test_char = preprocessing.preprocess(train_raw, test_raw)\n",
    "print \"Preprocessed the data\", time.time() - begin\n",
    "\n",
    "#train_word include a bunch of tags that train_char doesn't.\n",
    "\n",
    "# Assign ids to words\n",
    "vocab_list = list(vocab)\n",
    "vocab_list.sort()\n",
    "begin = time.time()\n",
    "vocab_dict = {}\n",
    "for i in range(len(vocab_list)):\n",
    "    vocab_dict[vocab_list[i]] = i\n",
    "print \"Assigned ids to words:\", time.time() - begin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0 My mom will not leave the slots... I might have her excorted out of here haha <URL>\n",
      "1 Black leggins on sale for <NUM> bucks.... SOLD!! I baught the remaining <NUM> of them! Holler!\n",
      "2 Scheuuuuuuuuu scores!!!!! <NUM>-<NUM> Riverhawksssssss!!!\n",
      "3 <REF> just got it too! lovin it!\n",
      "4 <REF> there is rigatoni parm in the fridge! Don't say I never game ya anything biatch :) <URL>\n",
      "5 I was just about to ask u the same question? Lol absurd <REPLY> <REF> <REF> who the eff is <REF>\n",
      "6 <REF> scheibers over? Wtf! Who invited him! Ill be over in a bit!\n",
      "7 Watching Chelsea Handler one night stand videos with <REF> & <REF> some of the most hilarious thing I've ever seen! Haha\n",
      "8 Tucked in bed at the one seven seven lol watching the real world & hoping to fall asleep somewhat early! Docs w the madge at <NUM>am! Eek!\n",
      "9 <REF> whoever ur pic is of kinda looks like u and its weirding me out lol!\n",
      "10 Hey <REF> we gotta get that RIT dye today to hook up your sexy woman undies....\n"
     ]
    }
   ],
   "source": [
    "print len(train_word)\n",
    "i = 0\n",
    "for user in train_word:\n",
    "    for tweet in train_word[user]:\n",
    "        if i > 10:\n",
    "            break\n",
    "        print i, tweet\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0 My mom will not leave the slots... I might have her excorted out of here haha \n",
      "1 Black leggins on sale for  bucks.... SOLD!! I baught the remaining  of them! Holler!\n",
      "2 Scheuuuuuuuuu scores!!!!! - Riverhawksssssss!!!\n",
      "3  just got it too! lovin it!\n",
      "4  there is rigatoni parm in the fridge! Don't say I never game ya anything biatch :) \n",
      "5 I was just about to ask u the same question? Lol absurd    who the eff is \n",
      "6  scheibers over? Wtf! Who invited him! Ill be over in a bit!\n",
      "7 Watching Chelsea Handler one night stand videos with  &  some of the most hilarious thing I've ever seen! Haha\n",
      "8 Tucked in bed at the one seven seven lol watching the real world & hoping to fall asleep somewhat early! Docs w the madge at am! Eek!\n",
      "9  whoever ur pic is of kinda looks like u and its weirding me out lol!\n",
      "10 Hey  we gotta get that RIT dye today to hook up your sexy woman undies....\n"
     ]
    }
   ],
   "source": [
    "print len(train_char)\n",
    "i = 0\n",
    "for user in train_char:\n",
    "    for tweet in train_char[user]:\n",
    "        if i > 10:\n",
    "            break\n",
    "        print i, tweet\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19731\n",
      "1043\n"
     ]
    }
   ],
   "source": [
    "# Build train and test set\n",
    "train = train_char\n",
    "test = test_char\n",
    "num_full_feats = features.get_num_full_feats(vocab_list)\n",
    "num_train_tweets = 0\n",
    "num_test_tweets = 0\n",
    "# num_train_tweets = np.count_nonzero(~np.isnan(train))\n",
    "# num_test_tweets = np.count_nonzero(~np.isnan(test))\n",
    "for author_id in train:\n",
    "    num_train_tweets += len(train[author_id])\n",
    "for author_id in test:\n",
    "    num_test_tweets += len(test[author_id])\n",
    "X_train = np.zeros((num_train_tweets, num_full_feats))\n",
    "y_train = np.zeros(num_train_tweets)\n",
    "X_test = np.zeros((num_test_tweets, num_full_feats))\n",
    "y_test = np.zeros(num_test_tweets)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for author_id in train:\n",
    "    for tweet in train[author_id]:\n",
    "        X_train[count, :] = features.get_full_feats(tweet, vocab_dict)\n",
    "        y_train[count] = author_id\n",
    "        count += 1\n",
    "print count\n",
    "\n",
    "count = 0\n",
    "for author_id in test:\n",
    "    for tweet in test[author_id]:\n",
    "        X_test[count, :] = features.get_full_feats(tweet, vocab_dict)\n",
    "        y_test[count] = author_id\n",
    "        count += 1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19731 1043\n",
      "9439\n",
      "['a', 'aaaaah', 'aaaahh', 'aaron', 'ab', 'abandoned', 'abc', 'abdc', 'ability', 'able', 'aborted', 'abortion', 'abortions', 'about', 'above', 'absolute', 'absolutely', 'absolutly', 'absurd', 'abt', 'ac', 'aca', 'academy', 'accent', 'accents', 'accept', 'acceptance', 'accepted', 'accepts', 'accident', 'accidentally', 'accidently', 'accidents', 'accomplished', 'according', 'account', 'accounts', 'acct', 'accurate', 'accused', 'accuses', 'acenteno', 'ache', 'ack', 'acknowledge', 'across', 'act', 'acted', 'actin', 'acting', 'action', 'actions', 'active', 'activist', 'activities', 'activity', 'actor', 'actors', 'actress', 'acts', 'actual', 'actually', 'ad', 'adam', 'adams', 'add', 'added', 'addict', 'addicted', 'addiction', 'addictive', 'addicts', 'adding', 'addison', 'additional', 'address', 'adjusting', 'adlibs', 'admiral', 'admit', 'adobe', 'adopted', 'adoptive', 'adorable', 'adore', 'adrian', 'adrianne', 'adrien', 'ads', 'adult', 'adultfriendfindercom', 'adults', 'advances', 'advantage', 'advent', 'adventure', 'adventures', 'advice', 'advisors', 'aerial', 'aerobics', 'afc', 'affect', 'affected', 'afford', 'afraid', 'african', 'afro', 'after', 'aftermath', 'afternoon', 'afterparty', 'afterwards', 'ag', 'again', 'against', 'againthanks', 'age', 'aged', 'agency', 'agent', 'agentorange', 'ages', 'aggies', 'agh', 'ago', 'agree', 'agreed', 'agrees', 'ah', 'aha', 'ahahaha', 'ahater', 'ahead', 'ahem', 'ahh', 'ahhh', 'ahhhh', 'ahhhhh', 'ahhhhhh', 'ahnold', 'ai', 'aid', 'aids', 'aim', 'aimed', 'aint', 'aintnothinglike', 'ainum', 'air', 'airboats', 'aired', 'airlift', 'airlines', 'airplane', 'airporeply', 'airport', 'airs', 'airtime', 'aj', 'ak', 'aka', 'al', 'alabama', 'alameda', 'alarm', 'albrecht', 'album', 'albums', 'albuquerque', 'alcohol', 'alcoholic', 'ale', 'alec', 'alejandro', 'alereply', 'alert', 'alex', 'alexander', 'algorithms', 'alguien', 'ali', 'alice', 'alicia', 'alien', 'aliens', 'alike', 'alis', 'alive', 'alka', 'all', 'allen', 'allergic', 'allergies', 'alleys', 'alli', 'alligators', 'allis', 'alll', 'allll', 'alllll', 'allllllll', 'allover', 'allow', 'allowed', 'allowing', 'allows', 'allstar', 'almfao', 'almighty', 'almost', 'alomst', 'alone', 'along', 'alot', 'alpha', 'already', 'alright', 'also', 'alter', 'altho', 'although', 'altima', 'alumni', 'always', 'alwys', 'alyssa', 'am', 'ama', 'amanda', 'amani', 'amazed', 'amazes', 'amazin', 'amazing', 'amazingly', 'amazon', 'amazoncom', 'amber', 'ambition', 'amd', 'amee', 'amen', 'amendment', 'amendments', 'america', 'american', 'americana', 'americanidol', 'americanized', 'americans', 'americas', 'ami', 'amid', 'amitheonlyone', 'among', 'amongst', 'amor', 'amount', 'amped', 'amused', 'amusement', 'amy', 'an', 'anal', 'anatomy', 'anchor', 'anchorman', 'anchors', 'and', 'anderson', 'andor', 'andrew', 'andy', 'angel', 'angeles', 'angelina', 'angelique', 'angelou', 'angels', 'anger', 'angry', 'animal', 'animals', 'animatronic', 'aniston', 'ankle', 'anna', 'anne', 'annie', 'anniversary', 'announce', 'announced', 'announces', 'announcing', 'annoy', 'annoyed', 'annoyin', 'annoying', 'annual', 'anonymous', 'anorexic', 'another', 'answer', 'answered', 'answering', 'answers', 'antes', 'anthony', 'anticipating', 'anticipation', 'antonio', 'ants', 'anxiety', 'any', 'anybody', 'anymore', 'anymoreugh', 'anynum', 'anyone', 'anyones', 'anything', 'anytime', 'anyway', 'anyways', 'anywhere', 'aowww', 'ap', 'apart', 'apocalypto', 'apologize', 'app', 'appaerently', 'appalled', 'apparently', 'appeal', 'appear', 'appearance', 'appetite', 'appetizers', 'apple', 'applebees', 'apples', 'application', 'applications', 'applied', 'applies', 'apply', 'applying', 'appointed', 'appointment', 'appreciate', 'appreciated', 'approach', 'approached', 'approve', 'approved', 'approx', 'apps', 'appt', 'april', 'aps', 'apt', 'aquarius', 'arab', 'arbys', 'ard', 'are', 'area', 'arena', 'arent', 'argentine', 'argue', 'arguing', 'argument', 'arguments', 'arizona', 'arkansas', 'arm', 'armenian', 'arms', 'armstrong', 'army', 'arnold', 'around', 'arrest', 'arrested', 'arrive', 'arrived', 'arrives', 'arriving', 'arrogant', 'art', 'artest', 'article', 'artificial', 'artist', 'artists', 'arts', 'artst', 'as', 'asa', 'asap', 'ash', 'ashley', 'ashton', 'ashy', 'asi', 'asian', 'asja', 'ask', 'askd', 'asked', 'askin', 'asking', 'asks', 'asleep', 'aspects', 'ass', 'assemble', 'asses', 'asshole', 'assholes', 'assi', 'assigned', 'assistance', 'assistant', 'asslol', 'association', 'assume', 'assuming', 'assured', 'asthma', 'at', 'atcha', 'ate', 'atl', 'atlanta', 'atlantic', 'atleast', 'atm', 'atmexicanparties', 'att', 'attack', 'attempt', 'attempting', 'attend', 'attended', 'attending', 'attention', 'attire', 'attitude', 'attn', 'attnum', 'attract', 'attracted', 'attractive', 'attttt', 'atty', 'atx', 'auburn', 'auction', 'audio', 'audition', 'auditioning', 'auditions', 'audrey', 'audy', 'audys', 'aunt', 'auntie', 'aunts', 'aurora', 'austin', 'australian', 'author', 'authorities', 'auto', 'autographed', 'automated', 'automatically', 'available', 'avatar', 'avble', 'ave', 'average', 'avg', 'avoid', 'aw', 'awake', 'award', 'awards', 'aware', 'awareness', 'away', 'awesome', 'awesomely', 'awful', 'awhile', 'awkward', 'aww', 'awww', 'awwww', 'awwwww', 'awwwwww', 'awwwwwwww', 'axis', 'ay', 'aye', 'ayo', 'azov', 'azul', 'azz', 'b', 'ba', 'babbbby', 'babby', 'babe', 'babes', 'babies', 'baby', 'babys', 'babysit', 'babysitter', 'babysitting', 'bacardi', 'bachata', 'bachelor', 'bachlorette', 'back', 'backed', 'backfire', 'background', 'backlight', 'backor', 'backs', 'backseat', 'backup', 'backups', 'backwards', 'backyard', 'bacon', 'bad', 'badass', 'badge', 'bag', 'bags', 'bahahaha', 'bahahahaha', 'bahahahahahaha', 'bail', 'bailey', 'bailout', 'baio', 'bait', 'bake', 'baked', 'bakery', 'baking', 'balance', 'bald', 'baldwin', 'ball', 'ballads', 'baller', 'ballers', 'ballin', 'balloon', 'balloonboy', 'balloons', 'balls', 'bam', 'bama', 'ban', 'banana', 'bananas', 'band', 'bandana', 'bandwagon', 'bang', 'bangin', 'banging', 'bangs', 'bank', 'banker', 'banks', 'banned', 'bar', 'barack', 'barbados', 'barbara', 'barber', 'barbers', 'barbershop', 'barbie', 'barcamp', 'bare', 'barely', 'barf', 'barfalicious', 'barnyard', 'barnyardbuster', 'baron', 'barrio', 'barry', 'bars', 'bartender', 'bartow', 'baseball', 'based', 'basement', 'bash', 'bashing', 'basic', 'basically', 'basket', 'basketball', 'bass', 'bastard', 'basterds', 'bat', 'batcave', 'bath', 'bathed', 'bathroom', 'batman', 'battery', 'battle', 'battleground', 'baught', 'baxter', 'bay', 'bayh', 'bayshore', 'bb', 'bball', 'bbc', 'bberry', 'bbl', 'bbm', 'bbms', 'bbq', 'bby', 'bbygirl', 'bc', 'bch', 'bck', 'bcs', 'bcuz', 'bday', 'be', 'beach', 'beaches', 'beacon', 'beads', 'beagle', 'beamer', 'bean', 'beaner', 'beans', 'bear', 'beard', 'bearing', 'bears', 'beas', 'beast', 'beat', 'beatcancer', 'beating', 'beatla', 'beatles', 'beats', 'beautiful', 'beautifully', 'beauty', 'beaver', 'beavers', 'bebe', 'became', 'because', 'becauseofpussy', 'beck', 'become', 'becomes', 'becomin', 'becoming', 'becuase', 'becuz', 'bed', 'bedroom', 'bedroommaybe', 'bedside', 'bedtime', 'bee', 'beecher', 'beef', 'been', 'beer', 'beers', 'bees', 'beezy', 'befor', 'before', 'begin', 'beginning', 'begins', 'begun', 'behind', 'beileve', 'bein', 'being', 'beings', 'bel', 'belief', 'believe', 'believed', 'believes', 'believing', 'bell', 'belleza', 'bells', 'belly', 'belmont', 'belong', 'belongs', 'beloved', 'below', 'ben', 'benched', 'bend', 'benedict', 'benefit', 'benefits', 'bengals', 'benicia', 'benny', 'bens', 'bent', 'bentley', 'benum', 'benz', 'berlin', 'bernie', 'berry', 'bert', 'beside', 'besides', 'bess', 'best', 'bestest', 'bestfeeling', 'bestfeelingever', 'bestfriend', 'bestfriends', 'bestie', 'besties', 'bet', 'bethiphopawards', 'bets', 'betsy', 'betta', 'better', 'betting', 'betty', 'between', 'bev', 'beverly', 'beware', 'bey', 'beyonce', 'beyonces', 'beyonc\\xc3\\xa9', 'beyond', 'bf', 'bff', 'bffs', 'bfs', 'bham', 'bi', 'biacco', 'biatch', 'bible', 'biblical', 'biden', 'bieber', 'biebers', 'bien', 'big', 'bigelow', 'bigger', 'biggest', 'biggestlooser', 'biggie', 'biggies', 'bike', 'bikes', 'biking', 'bikini', 'bill', 'billboard', 'billie', 'billion', 'bills', 'billy', 'bin', 'bingo', 'bio', 'bioccho', 'bipartisanship', 'bird', 'birdie', 'birdman', 'birds', 'bireplyhday', 'birmingham', 'birth', 'birthday', 'birthdays', 'biscuit', 'bisexual', 'bish', 'bishes', 'bit', 'bitch', 'bitches', 'bitchsowhat', 'bitchy', 'bite', 'bites', 'bitter', 'biz', 'bj', 'bjs', 'bk', 'bkgirls', 'bl', 'black', 'blackberry', 'blackberrygang', 'blackhistory', 'blackhistorymonth', 'blade', 'blah', 'blahhh', 'blair', 'blam', 'blame', 'blameciscosnutties', 'blameitontwitter', 'blank', 'blanket', 'blaring', 'blasphemy', 'blast', 'blasting', 'blaze', 'blazenaples', 'blazers', 'bldg', 'bleach', 'bleh', 'bless', 'blessed', 'blessin', 'blessing', 'blessings', 'blew', 'blind', 'blinded', 'bliss', 'blizzard', 'blnum', 'blo', 'block', 'blockbuster', 'blocked', 'blocks', 'blog', 'blogger', 'bloggers', 'blogging', 'blogs', 'blond', 'blonde', 'blood', 'blooded', 'bloods', 'bloody', 'blooming', 'blow', 'blowin', 'blowing', 'blown', 'blows', 'blue', 'blueprint', 'blues', 'blunt', 'blunted', 'blurb', 'blurry', 'blvd', 'bmore', 'bmw', 'bnum', 'bo', 'board', 'boarding', 'boast', 'boat', 'bob', 'bobby', 'bobsled', 'boccaccio', 'body', 'bodyguard', 'bodys', 'boggle', 'bogus', 'boi', 'bol', 'bold', 'bolt', 'bolts', 'bomb', 'bombed', 'bombing', 'bombs', 'bon', 'bond', 'bonding', 'bones', 'bonita', 'bonus', 'bonuses', 'boo', 'boob', 'boobies', 'boobs', 'boogie', 'book', 'booked', 'books', 'boom', 'booo', 'boos', 'boost', 'boot', 'booth', 'bootleg', 'boots', 'bootsy', 'booty', 'bore', 'bored', 'boredom', 'boring', 'born', 'borrow', 'borrowed', 'boss', 'bosses', 'boston', 'bot', 'both', 'bother', 'bothered', 'bothers', 'bots', 'bottle', 'bottles', 'bottom', 'bought', 'bounce', 'bouncy', 'bound', 'boundaries', 'bourbon', 'bout', 'bow', 'bowl', 'bowlers', 'bowling', 'bowls', 'box', 'boxer', 'boxers', 'boxing', 'boy', 'boyfriend', 'boyle', 'boyles', 'boys', 'boyz', 'bpm', 'bra', 'bracelets', 'braces', 'brad', 'brady']\n"
     ]
    }
   ],
   "source": [
    "print num_train_tweets, num_test_tweets\n",
    "print len(vocab_list) + 10\n",
    "print vocab_list[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 38.7238478661 acc: 0.499520613615 my_acc: 0.499520613615\n",
      "preds: [ 66457140.  33642976.  33642976. ...,  16118107.  27267971.  15770773.]\n",
      "scores: [[-4.76702935 -2.44682231 -2.07114997 ..., -0.22163771 -0.0446665\n",
      "  -2.2267857 ]\n",
      " [-0.67129826 -2.90154056 -2.41482495 ..., -1.58266047 -1.90258392\n",
      "  -1.8423281 ]\n",
      " [-2.79850719 -2.74949521 -2.13617798 ..., -0.6456651  -0.44391477\n",
      "  -1.96149118]\n",
      " ..., \n",
      " [-1.32865858 -0.49516445 -2.18064193 ..., -1.89772456 -1.13554934\n",
      "  -0.5980491 ]\n",
      " [-1.20346123 -2.14830664 -1.98571215 ..., -1.47166027 -2.4875359\n",
      "  -2.80340774]\n",
      " [-0.32081447 -0.75273429 -0.90622398 ..., -0.99160071 -0.68433676\n",
      "  -0.3614042 ]]\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "clf = model.train(X_train, y_train)\n",
    "acc, my_acc, preds, scores = model.test(clf, X_test, y_test)\n",
    "print 'time:', time.time()-begin, 'acc:', acc, 'my_acc:', my_acc\n",
    "print 'preds:', preds\n",
    "print 'scores:', scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False  True False False False False False False False\n",
      "  True  True  True  True False  True False False False  True False False\n",
      " False  True False  True  True  True  True False False  True False  True\n",
      " False  True False  True  True  True  True False  True  True False  True\n",
      "  True False False  True False False  True  True False False False False\n",
      "  True False  True  True False False  True  True  True  True  True False\n",
      " False  True False  True  True False False  True  True  True  True  True\n",
      " False  True  True  True False False False  True  True  True  True  True\n",
      "  True False  True  True]\n"
     ]
    }
   ],
   "source": [
    "print (preds == y_test)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "20078\n"
     ]
    }
   ],
   "source": [
    "print np.count_nonzero(scores > 0)\n",
    "print np.count_nonzero(scores < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for num_feats in range(2000, 10000, 2000):\n",
    "    begin = time.time()\n",
    "    idxs = feature_selection.select_features(X_train, y_train, np.zeros(features.get_num_full_feats(vocab_list)), num_feats, 'dia')\n",
    "    print \"Selected Features using DIA:\", begin - time.time()\n",
    "    X_train_dia = X_train[:, idxs]\n",
    "    X_test_dia = X_test[:, idxs]\n",
    "    begin = time.time()\n",
    "    clf = model.train(X_train_dia, y_train)\n",
    "    acc, my_acc, preds, scores = model.test(clf, X_test_dia, y_test)\n",
    "    print num_feats, 'acc:', acc, 'my_acc:', my_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for num_feats in range(2000, 10000, 2000):\n",
    "    begin = time.time()\n",
    "    idxs = feature_selection.select_features(X_train, y_train, np.zeros(features.get_num_full_feats(vocab_list)), num_feats, 'odds_ratio')\n",
    "    print \"Selected Features using Odds Ratio:\", begin - time.time()\n",
    "    X_train_or = X_train[:, idxs]\n",
    "    X_test_or = X_test[:, idxs]\n",
    "    begin = time.time()\n",
    "    clf = model.train(X_train_or, y_train)\n",
    "    acc, my_acc, preds, scores = model.test(clf, X_test_or, y_test)\n",
    "    print num_feats, 'acc:', acc, 'my_acc:', my_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "begin = time.time()\n",
    "idxs = feature_selection.select_features(X_train, y_train, np.zeros(features.get_num_full_feats(vocab_list)), 8000, 'dia')\n",
    "print \"Selected Features:\", begin - time.time()\n",
    "X_train_dia = X_train[:, idxs]\n",
    "X_test_dia = X_test[:, idxs]\n",
    "begin = time.time()\n",
    "clf = model.train(X_train_dia, y_train)\n",
    "acc, my_acc, preds, scores = model.test(clf, X_test_dia, y_test)\n",
    "print 'time:', time.time()-begin, 'acc:', acc, 'my_acc:', my_acc\n",
    "print 'preds:', preds\n",
    "print 'scores:', scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
