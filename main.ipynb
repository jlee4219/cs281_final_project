{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Selection.py\n",
      "Imported preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "import features\n",
    "import read\n",
    "import model\n",
    "import selection\n",
    "import preprocessing\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Features.py\n",
      "Imported read.py\n",
      "Imported model.py\n",
      "Imported Selection.py\n",
      "Imported preprocessing.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'preprocessing' from 'preprocessing.pyc'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Must reload each time you change a Python module\n",
    "reload(features)\n",
    "reload(read)\n",
    "reload(model)\n",
    "reload(selection)\n",
    "reload(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Train users: 20 Num of Test users: 20\n",
      "Read data: 224.786113024\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the text files\n",
    "begin = time.time()\n",
    "vocab, train_raw, test_raw = read.read_tweets(\"../training_set_tweets.txt\", \"../test_set_tweets.txt\")\n",
    "print \"Num of Train users:\", len(train_raw), \"Num of Test users:\", len(test_raw)\n",
    "print \"Read data:\", time.time() - begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the data 1.66138482094\n",
      "Assigned ids to words: 0.00963997840881\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "begin = time.time()\n",
    "vocab, train_word, test_word, train_char, test_char = preprocessing.preprocess(train_raw, test_raw)\n",
    "print \"Preprocessed the data\", time.time() - begin\n",
    "\n",
    "#train_word include a bunch of tags that train_char doesn't.\n",
    "\n",
    "# Assign ids to words\n",
    "vocab_list = list(vocab)\n",
    "vocab_list.sort()\n",
    "begin = time.time()\n",
    "vocab_dict = {}\n",
    "for i in range(len(vocab_list)):\n",
    "    vocab_dict[vocab_list[i]] = i\n",
    "print \"Assigned ids to words:\", time.time() - begin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0 The kittens r destroying the tree and the madge is not impressed lol\n",
      "1 <REF> Just finished up the rest of our costume stuff!!! Now to get this damn black paint out of my finger nails! Geese\n",
      "2 Babbbby keira!! :) yay!  <URL>\n",
      "3 <REF> dude ive got no time to watch chicks with dicks right now... nor does my blackberry battery! #getaclue\n",
      "4 Not pretty lezbos. Fat gat gross old dykes! Hotttt! <REPLY> <REF> Watching lesbians ride a mechanical bull and this is not a joke\n",
      "5 <REF> haha you'll have to go to encore one of these times when DJ <REF> is spinning!\n",
      "6 Making valentines day cards with ry for her classmates! She's to funny!\n",
      "7 <REF> forget about going to canada.... Shell be famous in the blo by morning lol :) <URL>\n",
      "8 <REF> hahah no! But we do have a yaya,  heavenly, orangejello and yellowjello... No joke lol <URL>\n",
      "9 Out shopping for stuff for gram! She's not having a good day today :/ blah!\n",
      "10 <REF> scheibers over? Wtf! Who invited him! Ill be over in a bit!\n"
     ]
    }
   ],
   "source": [
    "print len(train_word)\n",
    "i = 0\n",
    "for user in train_word:\n",
    "    for tweet in train_word[user]:\n",
    "        if i > 10:\n",
    "            break\n",
    "        print i, tweet\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0 The kittens r destroying the tree and the madge is not impressed lol\n",
      "1  Just finished up the rest of our costume stuff!!! Now to get this damn black paint out of my finger nails! Geese\n",
      "2 Babbbby keira!! :) yay!  \n",
      "3  dude ive got no time to watch chicks with dicks right now... nor does my blackberry battery! #getaclue\n",
      "4 Not pretty lezbos. Fat gat gross old dykes! Hotttt!   Watching lesbians ride a mechanical bull and this is not a joke\n",
      "5  haha you'll have to go to encore one of these times when DJ  is spinning!\n",
      "6 Making valentines day cards with ry for her classmates! She's to funny!\n",
      "7  forget about going to canada.... Shell be famous in the blo by morning lol :) \n",
      "8  hahah no! But we do have a yaya,  heavenly, orangejello and yellowjello... No joke lol \n",
      "9 Out shopping for stuff for gram! She's not having a good day today :/ blah!\n",
      "10  scheibers over? Wtf! Who invited him! Ill be over in a bit!\n"
     ]
    }
   ],
   "source": [
    "print len(train_char)\n",
    "i = 0\n",
    "for user in train_char:\n",
    "    for tweet in train_char[user]:\n",
    "        if i > 10:\n",
    "            break\n",
    "        print i, tweet\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19731\n",
      "1043\n"
     ]
    }
   ],
   "source": [
    "train = train_word\n",
    "test = test_word\n",
    "\n",
    "# Build train and test set\n",
    "num_full_feats = len(vocab_list) + 10\n",
    "num_train_tweets = 0\n",
    "num_test_tweets = 0\n",
    "# num_train_tweets = np.count_nonzero(~np.isnan(train))\n",
    "# num_test_tweets = np.count_nonzero(~np.isnan(test))\n",
    "for author_id in train:\n",
    "    num_train_tweets += len(train[author_id])\n",
    "for author_id in test:\n",
    "    num_test_tweets += len(test[author_id])\n",
    "X_train = np.zeros((num_train_tweets, num_full_feats))\n",
    "y_train = np.zeros(num_train_tweets)\n",
    "X_test = np.zeros((num_test_tweets, num_full_feats))\n",
    "y_test = np.zeros(num_test_tweets)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for author_id in train:\n",
    "    for tweet in train[author_id]:\n",
    "        X_train[count, :] = features.get_full_feats(tweet, vocab_dict)\n",
    "        y_train[count] = author_id\n",
    "        count += 1\n",
    "print count\n",
    "\n",
    "count = 0\n",
    "for author_id in test:\n",
    "    for tweet in test[author_id]:\n",
    "        X_test[count, :] = features.get_full_feats(tweet, vocab_dict)\n",
    "        y_test[count] = author_id\n",
    "        count += 1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19731 1043\n",
      "9475\n",
      "['a', 'aaaaah', 'aaaahh', 'aaron', 'ab', 'abandoned', 'abc', 'abdc', 'ability', 'able', 'aborted', 'abortions', 'abound', 'about', 'above', 'absolute', 'absolutely', 'absolutly', 'absurd', 'abt', 'ac', 'aca', 'academy', 'accent', 'accents', 'accept', 'acceptance', 'accepted', 'accepts', 'accident', 'accidentally', 'accidently', 'accidents', 'accomplished', 'according', 'account', 'accounts', 'acct', 'accurate', 'accused', 'accuses', 'acenteno', 'ache', 'ack', 'acknowledge', 'acnum', 'across', 'act', 'acted', 'actin', 'acting', 'action', 'actions', 'active', 'activist', 'activities', 'activity', 'actor', 'actors', 'actress', 'acts', 'actual', 'actually', 'ad', 'adam', 'adams', 'add', 'added', 'addict', 'addicted', 'addiction', 'addictive', 'addicts', 'adding', 'addison', 'additional', 'additions', 'address', 'adjusting', 'adlibs', 'admiral', 'admit', 'adobe', 'adopted', 'adoptive', 'adorable', 'adore', 'adrian', 'adrien', 'ads', 'adult', 'adults', 'advance', 'advances', 'advantage', 'advent', 'adventure', 'adventures', 'advice', 'advisors', 'aerial', 'aerobics', 'afc', 'affect', 'affected', 'afford', 'afraid', 'african', 'afro', 'after', 'aftermath', 'afternoon', 'afterparty', 'afters', 'aftershock', 'afterwards', 'ag', 'again', 'against', 'age', 'aged', 'agency', 'agent', 'ages', 'aggies', 'agh', 'ago', 'agree', 'agreed', 'agrees', 'ah', 'aha', 'ahahaha', 'ahater', 'ahead', 'ahem', 'ahh', 'ahhh', 'ahhhh', 'ahhhhh', 'ahhhhhh', 'ahnold', 'ai', 'aid', 'aids', 'aim', 'aimed', 'aint', 'aintnothinglike', 'ainum', 'air', 'airboats', 'aired', 'airlift', 'airlines', 'airplane', 'airporeply', 'airport', 'airs', 'airtime', 'aisle', 'aj', 'ak', 'aka', 'al', 'alabama', 'alameda', 'alarm', 'albrecht', 'album', 'albums', 'albuquerque', 'alcohol', 'alcoholic', 'ale', 'alec', 'alejandro', 'alereply', 'alert', 'alex', 'alexander', 'algorithms', 'alguien', 'ali', 'alice', 'alicia', 'alien', 'aliens', 'alike', 'alis', 'alive', 'alka', 'all', 'allen', 'allergic', 'allergies', 'alleys', 'alli', 'alligators', 'allis', 'alll', 'allll', 'alllll', 'allllllll', 'allover', 'allow', 'allowed', 'allowing', 'allows', 'allstar', 'almighty', 'almost', 'alomst', 'alone', 'along', 'alot', 'alpha', 'already', 'alright', 'also', 'alter', 'altho', 'although', 'altima', 'alum', 'alumni', 'always', 'alwys', 'alyssa', 'am', 'ama', 'amanda', 'amani', 'amazed', 'amazes', 'amazin', 'amazing', 'amazingly', 'amazon', 'amazoncom', 'amber', 'ambition', 'ambulance', 'amd', 'amee', 'amen', 'amendment', 'amendments', 'america', 'american', 'americana', 'americanidol', 'americanized', 'americans', 'americas', 'ami', 'amid', 'amitheonlyone', 'among', 'amongst', 'amor', 'amount', 'amped', 'amused', 'amusement', 'amy', 'an', 'anal', 'anatomy', 'anchor', 'anchorman', 'anchors', 'and', 'anderson', 'andor', 'andrew', 'andy', 'angel', 'angeles', 'angelina', 'angelique', 'angelou', 'angels', 'anger', 'angry', 'animal', 'animals', 'animatronic', 'aniston', 'ankle', 'anna', 'anne', 'annie', 'anniversary', 'announce', 'announced', 'announces', 'annoy', 'annoyed', 'annoyin', 'annoying', 'annual', 'anonymous', 'anorexic', 'another', 'answer', 'answered', 'answering', 'answers', 'antes', 'anthony', 'anticipating', 'anticipation', 'antonio', 'ants', 'anxiety', 'any', 'anybody', 'anymore', 'anymoreugh', 'anynum', 'anyone', 'anyones', 'anything', 'anytime', 'anyway', 'anyways', 'anywhere', 'aowww', 'ap', 'apart', 'apocalypto', 'apologize', 'app', 'appaerently', 'appalled', 'apparently', 'appeal', 'appear', 'appearance', 'appetite', 'appetizers', 'applaud', 'apple', 'applebees', 'apples', 'application', 'applications', 'applied', 'applies', 'apply', 'applying', 'appointed', 'appreciate', 'appreciated', 'approach', 'approached', 'approval', 'approve', 'approved', 'approx', 'apps', 'appt', 'april', 'apt', 'aquarius', 'arab', 'arbys', 'ard', 'are', 'area', 'arena', 'arent', 'argentine', 'argue', 'arguing', 'arguments', 'arizona', 'arkansas', 'arm', 'armenian', 'arms', 'armstrong', 'army', 'arnold', 'around', 'arrest', 'arrested', 'arrive', 'arrived', 'arrives', 'arriving', 'art', 'arte', 'artest', 'article', 'artificial', 'artist', 'artists', 'arts', 'artst', 'as', 'asap', 'ash', 'ashley', 'ashton', 'ashy', 'asi', 'asian', 'aside', 'asja', 'ask', 'askd', 'asked', 'askin', 'asking', 'asks', 'asleep', 'aspects', 'ass', 'asses', 'asshole', 'assholes', 'assi', 'assigned', 'assistance', 'assistant', 'association', 'assume', 'assuming', 'assured', 'asthma', 'at', 'atcha', 'ate', 'atl', 'atlanta', 'atlantic', 'atleast', 'atm', 'atmexicanparties', 'att', 'attack', 'attempt', 'attempting', 'attend', 'attended', 'attending', 'attention', 'attire', 'attitude', 'attn', 'attnum', 'attract', 'attracted', 'attractive', 'attttt', 'atty', 'atx', 'auburn', 'auction', 'audio', 'audition', 'auditioning', 'auditions', 'audrey', 'audy', 'audys', 'aunt', 'auntie', 'aunts', 'aurora', 'austin', 'australian', 'author', 'authorities', 'auto', 'autographed', 'automated', 'automatically', 'available', 'avatar', 'avble', 'ave', 'average', 'avg', 'avoid', 'aw', 'awake', 'award', 'awards', 'aware', 'awareness', 'away', 'awesome', 'awful', 'awhile', 'awkward', 'aww', 'awwthats', 'awww', 'awwwd', 'awwww', 'awwwww', 'awwwwww', 'awwwwwwww', 'axis', 'ay', 'aye', 'ayo', 'azov', 'azul', 'b', 'ba', 'babbbby', 'babby', 'babe', 'babes', 'babies', 'baby', 'babys', 'babysit', 'babysitter', 'babysitting', 'bacardi', 'bachata', 'bachelor', 'bachlorette', 'back', 'backed', 'backfire', 'background', 'backlight', 'backor', 'backs', 'backseat', 'backup', 'backups', 'backwards', 'backyard', 'bacon', 'bad', 'badass', 'badge', 'bag', 'bags', 'bahahaha', 'bahahahahahaha', 'bail', 'bailey', 'bailout', 'baio', 'bait', 'bake', 'baked', 'bakery', 'baking', 'balance', 'bald', 'baldwin', 'ball', 'ballads', 'baller', 'ballers', 'ballin', 'balloon', 'balloonboy', 'balloons', 'balls', 'bam', 'bama', 'ban', 'banana', 'bananas', 'band', 'bandwagon', 'bang', 'bangin', 'banging', 'bangs', 'bank', 'banker', 'banks', 'banned', 'banquet', 'bar', 'barack', 'barbados', 'barbara', 'barber', 'barbers', 'barbershop', 'barbie', 'barcamp', 'bare', 'barely', 'barf', 'barfalicious', 'barnyard', 'barnyardbuster', 'baron', 'barrio', 'barry', 'bars', 'bartender', 'bartow', 'baseball', 'based', 'basement', 'bash', 'bashing', 'basic', 'basically', 'basketball', 'bass', 'bastard', 'basterds', 'bat', 'batcave', 'bath', 'bathed', 'bathroom', 'batman', 'battery', 'battle', 'battleground', 'baught', 'baxter', 'bay', 'bayh', 'bayshore', 'bb', 'bball', 'bbc', 'bberry', 'bbl', 'bbm', 'bbms', 'bbq', 'bby', 'bbygirl', 'bc', 'bch', 'bck', 'bcuz', 'bday', 'bdubs', 'be', 'beach', 'beaches', 'beacon', 'beads', 'beagle', 'beamer', 'bean', 'beaner', 'beans', 'bear', 'beard', 'bearing', 'bears', 'beas', 'beast', 'beat', 'beatcancer', 'beating', 'beatla', 'beatles', 'beats', 'beautiful', 'beautifully', 'beauty', 'beaver', 'beavers', 'bebe', 'became', 'because', 'becauseofpussy', 'beck', 'become', 'becomes', 'becomin', 'becoming', 'becuase', 'becuz', 'bed', 'bedroom', 'bedroommaybe', 'bedside', 'bedtime', 'bee', 'beecher', 'beef', 'been', 'beer', 'beers', 'bees', 'beezy', 'befor', 'before', 'begging', 'begin', 'beginning', 'begins', 'begun', 'behind', 'beileve', 'bein', 'being', 'beings', 'bel', 'belief', 'believe', 'believed', 'believes', 'believing', 'bell', 'bella', 'belleza', 'bells', 'belly', 'belmont', 'belong', 'beloved', 'below', 'ben', 'benched', 'bend', 'benedict', 'benefit', 'benefits', 'bengals', 'benicia', 'benny', 'bens', 'bent', 'bentley', 'benum', 'benz', 'berlin', 'bernie', 'berry', 'bert', 'beside', 'besides', 'bess', 'best', 'bestest', 'bestfeeling', 'bestfeelingever', 'bestfriend', 'bestfriends', 'bestie', 'besties', 'bet', 'bethiphopawards', 'bets', 'betsy', 'betta', 'better', 'betting', 'betty', 'between', 'bev', 'beverly', 'beware', 'bey', 'beyonce', 'beyonces', 'beyonc\\xc3\\xa9', 'beyond', 'bf', 'bff', 'bffs', 'bfs', 'bgc', 'bham', 'bi', 'biacco', 'biatch', 'bible', 'biblical', 'biden', 'bieber', 'biebers', 'bien', 'big', 'bigelow', 'bigger', 'biggest', 'biggestlooser', 'biggie', 'biggies', 'bike', 'bikes', 'biking', 'bikini', 'bilan', 'bill', 'billboard', 'billie', 'billion', 'bills', 'billy', 'bin', 'bingo', 'bio', 'bioccho', 'bipartisanship', 'bird', 'birdie', 'birdman', 'birds', 'bireplyhday', 'birmingham', 'birth', 'birthday', 'birthdays', 'biscuit', 'bisexual', 'bish', 'bishes', 'bit', 'bitch', 'bitches', 'bitchsowhat', 'bitchy', 'bite', 'bites', 'bitter', 'biz', 'bj', 'bjs', 'bk', 'bkgirls', 'bl', 'black', 'blackberry', 'blackberrygang', 'blackhistory', 'blackhistorymonth', 'blade', 'blah', 'blahhh', 'blair', 'blam', 'blame', 'blameciscosnutties', 'blameitontwitter', 'blank', 'blanket', 'blaring', 'blasphemy', 'blast', 'blasted', 'blasting', 'blaze', 'blazenaples', 'blazers', 'bldg', 'bleach', 'blech', 'bleh', 'bless', 'blessed', 'blessin', 'blessing', 'blessings', 'blew', 'blind', 'blinded', 'bliss', 'blizzard', 'blnum', 'blo', 'block', 'blockbuster', 'blocked', 'blocks', 'blog', 'bloggers', 'blogging', 'blogs', 'blond', 'blonde', 'blood', 'blooded', 'bloods', 'bloody', 'blooming', 'blow', 'blowin', 'blowing', 'blown', 'blows', 'blue', 'blueprint', 'blues', 'blunt', 'blunted', 'bluray', 'blurb', 'blurry', 'blvd', 'bmore', 'bmw', 'bnum', 'bo', 'board', 'boarding', 'boast', 'boat', 'bob', 'bobsled', 'boccaccio', 'body', 'bodys', 'boggle', 'bogus', 'bol', 'bold', 'bolt', 'bolts', 'bomb', 'bombed', 'bombing', 'bombs', 'bon', 'bond', 'bonding', 'bones', 'bonita', 'bonuses', 'boo', 'boob', 'boobies', 'boobs', 'book', 'booked', 'books', 'boom', 'booo', 'boos', 'boost', 'boot', 'booth', 'bootleg', 'boots', 'bootsy', 'booty', 'bore', 'bored', 'boredom', 'boring', 'boris', 'born', 'borrow', 'borrowed', 'boss', 'bosses', 'boston', 'bot', 'both', 'bother', 'bothered', 'bothers', 'bots', 'bottle', 'bottles', 'bottom', 'bought', 'bounce', 'bouncy', 'bound', 'boundaries', 'bourbon', 'bout', 'bow', 'bowl', 'bowlers', 'bowling', 'bowls', 'box', 'boxer', 'boxers', 'boxes', 'boxing', 'boy', 'boyfriend', 'boyle', 'boyles', 'boys', 'boyz', 'bpm', 'bracelets', 'braces', 'brad', 'brady', 'braided', 'brain']\n"
     ]
    }
   ],
   "source": [
    "print num_train_tweets, num_test_tweets\n",
    "print len(vocab_list) + 10\n",
    "print vocab_list[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial num of features: 9475\n",
      "selectivity: 0.8 cutoff: 7580.0\n",
      "8528 947\n",
      "[12, 972, 1487, 1842, 2319, 2512, 2632, 2737, 2771, 4161]\n",
      "7581 947\n",
      "[4103, 4942, 2379, 807, 6804, 8130, 2135, 1003, 5685, 3004]\n",
      "6634 947\n",
      "[1413, 4846, 4031, 3472, 3460, 7184, 5941, 6971, 7049, 2555]\n",
      "Feature selection: 62.2929229736\n"
     ]
    }
   ],
   "source": [
    "# print X_train[:10]\n",
    "# print X_test[:10]\n",
    "\n",
    "#Normalization\n",
    "begin = time.time()\n",
    "X_min = np.min(X_train, axis=0)\n",
    "X_max = np.max(X_train, axis=0)\n",
    "# print X_min[:100]\n",
    "# print X_max[:100]\n",
    "# X_train = (X_train - X_min) / (X_max - X_min)\n",
    "# X_test = (X_test - X_min) / (X_max - X_min)\n",
    "# X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "# X_test = (X_test - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "# print 'Normalized:', time.time()-begin\n",
    "# print X_train[:10]\n",
    "# print X_test[:10]\n",
    "\n",
    "#Feature selection\n",
    "begin = time.time()\n",
    "X_train_selected, X_test_selected = selection.selectSVM_RFE(X_train, y_train, X_test, 0.8)\n",
    "print 'Feature selection:', time.time()-begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19731, 6634)\n",
      "(1043, 6634)\n"
     ]
    }
   ],
   "source": [
    "print X_train_selected.shape\n",
    "print X_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.2224619389 acc: 0.503355704698 my_acc: 0.503355704698\n",
      "preds: [ 33642976.  33642976.  66457140. ...,  15770773.  72413117.  37604616.]\n",
      "scores: [[ 3.24514139  1.50536672  0.46082104 ...,  3.84367871  3.45375766\n",
      "   3.49938786]\n",
      " [ 1.22078206  1.39034509  1.92741198 ...,  1.73016722  0.91508602\n",
      "   1.0697402 ]\n",
      " [ 2.01504838  2.72073607  1.67779326 ...,  3.93989136  0.14714615\n",
      "   3.59375088]\n",
      " ..., \n",
      " [ 0.19152795  2.42966658  1.08028529 ...,  2.20499287  0.29321204\n",
      "   2.8326853 ]\n",
      " [ 0.77533566  1.87119061  1.79950901 ...,  0.97608674  1.05702999\n",
      "   0.54858154]\n",
      " [ 0.82760047  1.60998639  2.18130021 ...,  0.3992331   1.77365834\n",
      "   1.57643337]]\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "clf = model.train(X_train, y_train)\n",
    "acc, my_acc, preds, scores = model.test(clf, X_test, y_test)\n",
    "print 'time:', time.time()-begin, 'acc:', acc, 'my_acc:', my_acc\n",
    "print 'preds:', preds\n",
    "print 'scores:', scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.1808710098 acc: 0.511025886865 my_acc: 0.511025886865\n",
      "preds: [ 33642976.  33642976.  66457140. ...,  66457140.  15770773.  37604616.]\n",
      "scores: [[ 2.90996986  2.58428929  0.8360142  ...,  3.07586974  3.14365264\n",
      "   3.77956925]\n",
      " [ 0.94311395  1.26468913  1.91872156 ...,  1.59535203  0.90223409\n",
      "   0.87166202]\n",
      " [ 1.73262556  2.87659195  2.15991368 ...,  3.46651724  0.2529098\n",
      "   2.77602794]\n",
      " ..., \n",
      " [ 0.67501484  2.38758363  0.77927251 ...,  2.15416425  0.33904485\n",
      "   2.60098672]\n",
      " [ 0.32899005  1.44999031  1.8183448  ...,  0.86587552  0.86269996\n",
      "   0.54844832]\n",
      " [ 0.64589044  1.50340508  1.94332497 ...,  0.65934652  1.8791517\n",
      "   1.20103461]]\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "clf = model.train(X_train_selected, y_train)\n",
    "acc, my_acc, preds, scores = model.test(clf, X_test_selected, y_test)\n",
    "print 'time:', time.time()-begin, 'acc:', acc, 'my_acc:', my_acc\n",
    "print 'preds:', preds\n",
    "print 'scores:', scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True  True False False  True False  True  True  True\n",
      " False False  True  True  True False  True  True  True  True False False\n",
      " False False  True  True  True False  True False False  True  True  True\n",
      "  True  True  True False  True False False False  True False False  True\n",
      "  True False  True  True  True  True False False  True  True  True False\n",
      "  True  True  True  True  True False False  True False False False False\n",
      " False  True False  True  True  True  True  True  True  True  True False\n",
      "  True False False  True  True False False  True  True  True  True False\n",
      "  True  True  True False]\n"
     ]
    }
   ],
   "source": [
    "print (preds == y_test)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0caf0b1a18c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "print np.count_nonzero(scores > 0)\n",
    "print np.count_nonzero(scores < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
